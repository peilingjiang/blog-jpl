<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on JPL BLOG</title>
    <link>https://blog.jpl.design/</link>
    <description>Recent content in Home on JPL BLOG</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://blog.jpl.design/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Glance of AI</title>
      <link>https://blog.jpl.design/posts/machine-learning-for-the-arts/a-glance-of-ai/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.jpl.design/posts/machine-learning-for-the-arts/a-glance-of-ai/</guid>
      <description>A Glance of AI How to say Hi in Klingonese?  In this section a task and corresponding AI system will be designed.
 Klingonese is an artificial alien language, every word of which is well documented and can be easily looked up by Star Trek fans. But when we&amp;rsquo;re faced with real Aliens, in like 100 years, we&amp;rsquo;ll have to listen to languages we&amp;rsquo;ve never heard of before. We&amp;rsquo;ll know nothing about the vocabulary, grammar, or structure, and we&amp;rsquo;ll have no family or root languages to compare to.</description>
    </item>
    
    <item>
      <title>ImageNet</title>
      <link>https://blog.jpl.design/posts/machine-learning-for-the-arts/imagenet/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.jpl.design/posts/machine-learning-for-the-arts/imagenet/</guid>
      <description>ImageNet The first thing that amazed me was that the project of ImageNet took full advantage of WordNet and benefited from Mechanical Turk. In this way, the data is so organized by synonym sets and, sounds crazy, human-annotated. The data can be looked up easily through treemap visualization.
While each syntex, as claimed, has more than 1000 images on average to be illustrated, I still found some weak portions. With only 138 picture for People section, a lot of subdivisions, including business people and lobby boy, have no photos.</description>
    </item>
    
    <item>
      <title>One Story</title>
      <link>https://blog.jpl.design/posts/communications-lab/one-story/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.jpl.design/posts/communications-lab/one-story/</guid>
      <description>One Story &amp;ndash; Reflection on Chimamanda Ngozi Adichieâ€™s TED talk [1].
Making one story the only story might be dangerous, but inevitable.
It&amp;rsquo;s true that each press, media, or storyteller might have their own perspectives, but it&amp;rsquo;s also true that they are all under certain meta narratives [2]. Social media have granted us countless resources of information, but we still feel the cyberspace bias. We could imagine looking into a mirror broken into pieces reflecting the world around, the reflection will be different but not much if all of them are on one flat floor.</description>
    </item>
    
    <item>
      <title>I, Avatar</title>
      <link>https://blog.jpl.design/posts/performative-avatars/i-avatar/</link>
      <pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://blog.jpl.design/posts/performative-avatars/i-avatar/</guid>
      <description>I, Avatar Hundreds of Avatar making softwares are there for tuning our digital representations as the expectations. Specialized softwares like Adobe Fuse and MakeHuman; Sculpting softwares like Cinema4D and blender; Social media like Facebook and twitter; Mobile apps like Memoji and Kapu&amp;hellip;
Here I used Fuse (beta) and Kapu, a newly released app by Tencent (the largest game company on the planet), created two very distinguishable Avatars of me, and analyzed the differences.</description>
    </item>
    
  </channel>
</rss>